import requests
import pandas as pd
import time
from datetime import datetime, timedelta
import json

# === 1. é…ç½®éƒ¨åˆ†ï¼ˆä¿æŒä¸å˜ï¼‰ ===
GITHUB_TOKEN = 'å¾…æ›¿æ¢'  # æ›¿æ¢ä¸ºä½ çš„token
HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}
BASE_URL = 'https://api.github.com'


# === 2. åŸºç¡€æœç´¢å‡½æ•°ï¼ˆéœ€ä¿ç•™æˆ–æ›¿æ¢ï¼‰ ===
def search_github_with_query(query, max_repos, headers):
    """æ ¹æ®å•ä¸ªæŸ¥è¯¢è¯­å¥æœç´¢ä»“åº“"""
    repos = []
    page = 1
    per_page = 100

    while len(repos) < max_repos:
        url = f'{BASE_URL}/search/repositories'
        params = {
            'q': query,
            'sort': 'updated',
            'order': 'desc',
            'page': page,
            'per_page': per_page
        }

        print(f'  æ­£åœ¨è·å–ç¬¬ {page} é¡µ...', end='')
        response = requests.get(url, headers=headers, params=params)

        if response.status_code != 200:
            print(f' å¤±è´¥! çŠ¶æ€ç ï¼š{response.status_code}')
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°APIé™åˆ¶
            if response.status_code == 403:
                reset_time = response.headers.get('X-RateLimit-Reset')
                if reset_time:
                    wait_seconds = int(reset_time) - int(time.time())
                    print(f'APIé™åˆ¶ï¼Œç­‰å¾… {wait_seconds} ç§’...')
                    time.sleep(max(wait_seconds, 1))
                    continue
            break

        data = response.json()
        page_repos = data.get('items', [])

        if not page_repos:
            print(' æ²¡æœ‰æ›´å¤šç»“æœ')
            break

        repos.extend(page_repos)
        print(f' æˆåŠŸï¼Œæœ¬é¡µè·å– {len(page_repos)} ä¸ªï¼Œç´¯è®¡ {len(repos)} ä¸ª')

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°APIè¿”å›çš„æ€»æ•°é™åˆ¶
        if len(repos) >= min(data.get('total_count', 0), max_repos):
            break

        page += 1
        time.sleep(1)  # é¿å…è§¦å‘æ¬¡çº§é™æµ

    return repos[:max_repos]


# === 3. æ–°çš„å¹³è¡¡æŠ“å–ç­–ç•¥ï¼ˆæ›¿æ¢åŸæœ‰çš„ç®€å•æœç´¢ï¼‰ ===
def fetch_balanced_repository_sample():
    """
    è·å–å¹³è¡¡çš„ä»“åº“æ ·æœ¬
    è¿”å›ï¼šä»“åº“å­—å…¸åˆ—è¡¨
    """

    # è®¡ç®—åŠ¨æ€æ—¥æœŸèŒƒå›´ï¼ˆå§‹ç»ˆç›¸å¯¹å½“å‰æ—¶é—´ï¼‰
    def get_date_ranges():
        today = datetime.now()
        eighteen_months_ago = (today - timedelta(days=30 * 18)).strftime('%Y-%m-%d')
        twelve_months_ago = (today - timedelta(days=30 * 12)).strftime('%Y-%m-%d')
        six_months_ago = (today - timedelta(days=30 * 6)).strftime('%Y-%m-%d')
        three_months_ago = (today - timedelta(days=30 * 3)).strftime('%Y-%m-%d')
        return eighteen_months_ago, twelve_months_ago, six_months_ago, three_months_ago

    start_18m, start_12m, start_6m, start_3m = get_date_ranges()

    # å®šä¹‰å››ä¸ªäº’è¡¥çš„æœç´¢ç­–ç•¥
    search_strategies = [
        {
            'name': 'python_diverse_stars',
            'query': f'created:{start_12m}..{start_6m} stars:5..300 pushed:>{start_3m} language:python',
            'target_count': 250,
            'description': 'Pythoné¡¹ç›®ï¼Œä¸­ç­‰StarèŒƒå›´ï¼Œç¡®ä¿æ´»è·ƒåº¦'
        },
        {
            'name': 'js_ts_newer_projects',
            'query': f'created:{start_6m}..now stars:1..100 pushed:>{start_3m} language:javascript,typescript',
            'target_count': 200,
            'description': 'JS/TSæ–°é¡¹ç›®ï¼Œè¾ƒä½Staræ•°'
        },
        {
            'name': 'emerging_languages',
            'query': f'created:{start_12m}..now stars:3..200 pushed:>{start_3m} language:go,rust,kotlin,swift',
            'target_count': 200,
            'description': 'æ–°å…´è¯­è¨€é¡¹ç›®ï¼ŒæŠ€æœ¯æ ˆå¤šæ ·'
        },
        {
            'name': 'mixed_lang_moderate',
            'query': f'created:{start_12m}..{start_6m} stars:10..150 pushed:>{start_3m}',
            'target_count': 150,
            'description': 'æ··åˆè¯­è¨€ï¼Œé¿å…è¯­è¨€è¿‡æ»¤åå·®'
        }
    ]

    all_repos = []

    print("ğŸš€ å¼€å§‹æ‰§è¡Œå¹³è¡¡æ•°æ®æŠ“å–ç­–ç•¥")
    print("=" * 60)

    for i, strategy in enumerate(search_strategies, 1):
        print(f"\nç­–ç•¥ {i}/{len(search_strategies)}: {strategy['name']}")
        print(f"æè¿°: {strategy['description']}")
        print(f"æŸ¥è¯¢: {strategy['query']}")
        print(f"ç›®æ ‡æ•°é‡: {strategy['target_count']}")

        try:
            repos = search_github_with_query(
                strategy['query'],
                strategy['target_count'],
                HEADERS
            )
            all_repos.extend(repos)
            print(f"âœ… æˆåŠŸè·å–: {len(repos)} ä¸ªä»“åº“")

            # æ˜¾ç¤ºæœ¬æ‰¹æ¬¡çš„ç®€å•ç»Ÿè®¡
            if repos:
                stars = [r.get('stargazers_count', 0) for r in repos]
                langs = [r.get('language', 'Unknown') for r in repos]
                print(f"   å¹³å‡Staræ•°: {sum(stars) / len(stars):.1f}")
                print(f"   è¯­è¨€åˆ†å¸ƒ: {pd.Series(langs).value_counts().head(3).to_dict()}")

        except Exception as e:
            print(f"âŒ ç­–ç•¥æ‰§è¡Œå¤±è´¥: {strategy['name']}")
            print(f"   é”™è¯¯: {e}")

        if i < len(search_strategies):
            print(f"ç­‰å¾…2ç§’ï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ªç­–ç•¥...")
            time.sleep(2)

    # === 4. å»é‡å’Œæ•´ç† ===
    print(f"\n{'=' * 60}")
    print("ğŸ“¦ æ•°æ®æ•´ç†é˜¶æ®µ")

    # åŸºäºIDå»é‡
    seen_ids = set()
    unique_repos = []

    for repo in all_repos:
        repo_id = repo['id']
        if repo_id not in seen_ids:
            seen_ids.add(repo_id)
            unique_repos.append(repo)

    print(f"å»é‡å‰: {len(all_repos)} ä¸ªä»“åº“")
    print(f"å»é‡å: {len(unique_repos)} ä¸ªå”¯ä¸€ä»“åº“")

    # === 5. å¯¼å‡ºåŸºæœ¬ä¿¡æ¯ä¾›éªŒè¯ ===
    if unique_repos:
        # æå–å…³é”®ä¿¡æ¯
        repo_data = []
        for repo in unique_repos:
            repo_info = {
                'id': repo['id'],
                'full_name': repo['full_name'],
                'html_url': repo['html_url'],
                'created_at': repo['created_at'],
                'updated_at': repo['updated_at'],
                'pushed_at': repo['pushed_at'],
                'stargazers_count': repo['stargazers_count'],
                'forks_count': repo['forks_count'],
                'open_issues_count': repo['open_issues_count'],
                'language': repo['language'],
                'topics': ', '.join(repo.get('topics', [])),
                'description': repo['description']
            }
            repo_data.append(repo_info)

        # ä¿å­˜åˆ°CSV
        df = pd.DataFrame(repo_data)
        output_file = '../../../Tree/readme/balanced_github_repositories.csv'
        df.to_csv(output_file, index=False, encoding='utf-8-sig')

        # å¿«é€Ÿç»Ÿè®¡
        print(f"\nğŸ“Š æ•°æ®é›†å¿«é€Ÿç»Ÿè®¡:")
        print(f"   æ€»é¡¹ç›®æ•°: {len(df)}")
        print(f"   Staræ•°èŒƒå›´: {df['stargazers_count'].min()} - {df['stargazers_count'].max()}")
        print(f"   å¹³å‡Staræ•°: {df['stargazers_count'].mean():.1f}")
        print(f"   ä¸­ä½æ•°Staræ•°: {df['stargazers_count'].median():.1f}")
        print(f"   è¯­è¨€ç§ç±»: {df['language'].nunique()}")
        print(
            f"   é›¶Staré¡¹ç›®: {(df['stargazers_count'] == 0).sum()} ({(df['stargazers_count'] == 0).mean() * 100:.1f}%)")

        # è¯­è¨€åˆ†å¸ƒ
        print(f"\n   å‰5å¤§è¯­è¨€:")
        lang_dist = df['language'].value_counts().head(5)
        for lang, count in lang_dist.items():
            pct = count / len(df) * 100
            lang_display = lang if pd.notna(lang) else 'Unknown'
            print(f"     {lang_display}: {count} ({pct:.1f}%)")

        print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {output_file}")

    return unique_repos


# === 6. æ‰§è¡ŒæŠ“å–ï¼ˆè¿™æ˜¯ä½ éœ€è¦è°ƒç”¨çš„éƒ¨åˆ†ï¼‰ ===
if __name__ == "__main__":
    print("å¼€å§‹æ‰§è¡Œæ”¹è¿›çš„æ•°æ®æŠ“å–...")
    print("=" * 60)

    try:
        # è°ƒç”¨æ–°çš„å¹³è¡¡æŠ“å–å‡½æ•°
        repositories = fetch_balanced_repository_sample()

        print("\n" + "=" * 60)
        print("âœ… æ•°æ®æŠ“å–å®Œæˆ!")

        # éªŒè¯æ•°æ®è´¨é‡
        if repositories:
            # è½¬æ¢ä¸ºDataFrameç”¨äºéªŒè¯
            df_test = pd.DataFrame([{
                'id': r['id'],
                'name': r['full_name'],
                'stars': r['stargazers_count'],
                'language': r['language'],
                'created_at': r['created_at']
            } for r in repositories])

            # è¿è¡Œæˆ‘ä»¬ä¹‹å‰çš„æ•°æ®è´¨é‡éªŒè¯
            from datetime import datetime

            df_test['created_at'] = pd.to_datetime(df_test['created_at']).dt.tz_localize(None)
            df_test['project_age_days'] = (datetime.now() - df_test['created_at']).dt.days

            print("\nğŸ“ˆ æœ€ç»ˆæ•°æ®è´¨é‡æ£€æŸ¥:")
            print(f"   æ ·æœ¬å¤§å°: {len(df_test)} ä¸ªé¡¹ç›®")
            print(f"   Starä¸­ä½æ•°: {df_test['stars'].median()}")
            print(f"   é›¶Staré¡¹ç›®æ¯”ä¾‹: {(df_test['stars'] == 0).mean() * 100:.1f}%")
            print(f"   è¯­è¨€å¤šæ ·æ€§: {df_test['language'].nunique()} ç§ä¸åŒè¯­è¨€")

            # ä¿å­˜è¯¦ç»†æ•°æ®
            detailed_data = []
            for repo in repositories:
                detailed_data.append({
                    'full_name': repo['full_name'],
                    'stars': repo['stargazers_count'],
                    'forks': repo['forks_count'],
                    'language': repo['language'],
                    'created_at': repo['created_at'],
                    'pushed_at': repo['pushed_at'],
                    'topics': ', '.join(repo.get('topics', [])),
                    'description': repo.get('description', ''),
                    'html_url': repo['html_url']
                })

            detailed_df = pd.DataFrame(detailed_data)
            detailed_df.to_csv('detailed_balanced_repos.csv', index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ è¯¦ç»†æ•°æ®å·²ä¿å­˜è‡³: detailed_balanced_repos.csv")

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æŠ“å–è¿‡ç¨‹")
    except Exception as e:
        print(f"\nâŒ æŠ“å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()