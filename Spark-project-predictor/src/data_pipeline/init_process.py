import pandas as pd
import numpy as np
from datetime import datetime


def refine_activity_classification(df):
    """è°ƒæ•´æ´»è·ƒåº¦åˆ†ç±» - ä¿®å¤æ—¶åŒºé—®é¢˜ç‰ˆæœ¬"""

    print("ğŸ•’ å¤„ç†æ—¶åŒºé—®é¢˜å¹¶è®¡ç®—æ´»è·ƒåº¦...")

    # æ–¹æ³•1ï¼šç»Ÿä¸€æ—¶åŒºï¼ˆæ¨èï¼‰
    # å°†å½“å‰æ—¶é—´è½¬æ¢ä¸ºUTCæ—¶åŒº
    current_time_utc = pd.Timestamp.now(tz='UTC')

    # ç¡®ä¿pushed_atåˆ—æ˜¯datetimeç±»å‹ä¸”æœ‰æ—¶åŒºä¿¡æ¯
    if not pd.api.types.is_datetime64_any_dtype(df['pushed_at']):
        df['pushed_at'] = pd.to_datetime(df['pushed_at'], utc=True)
    elif df['pushed_at'].dt.tz is None:
        # å¦‚æœdatetimeåˆ—æ²¡æœ‰æ—¶åŒºï¼Œæ·»åŠ UTCæ—¶åŒº
        df['pushed_at'] = df['pushed_at'].dt.tz_localize('UTC')

    # è®¡ç®—å¤©æ•°å·®
    df['days_since_last_update'] = (current_time_utc - df['pushed_at']).dt.days

    print(f"  æœ€è¿‘æ›´æ–°ç»Ÿè®¡:")
    print(f"    å¹³å‡ {df['days_since_last_update'].mean():.1f} å¤©å‰æ›´æ–°")
    print(f"    ä¸­ä½æ•° {df['days_since_last_update'].median():.1f} å¤©å‰æ›´æ–°")

    # æ›´ç²¾ç»†çš„æ´»è·ƒåº¦åˆ†ç±»
    def classify_activity_refined(days):
        if days <= 7:
            return 'éå¸¸æ´»è·ƒ(â‰¤7å¤©)'
        elif days <= 30:
            return 'æ´»è·ƒ(8-30å¤©)'
        elif days <= 90:
            return 'ä¸€èˆ¬æ´»è·ƒ(31-90å¤©)'
        elif days <= 180:
            return 'ä½æ´»è·ƒ(91-180å¤©)'
        else:
            return 'å¯èƒ½åœæ»(>180å¤©)'

    df['activity_level_refined'] = df['days_since_last_update'].apply(classify_activity_refined)

    # ç»Ÿè®¡æ–°åˆ†ç±»
    activity_dist = df['activity_level_refined'].value_counts()
    print("\nğŸ“Š è°ƒæ•´åçš„æ´»è·ƒåº¦åˆ†å¸ƒ:")
    for level, count in activity_dist.items():
        pct = count / len(df) * 100
        print(f"  {level}: {count}ä¸ªé¡¹ç›® ({pct:.1f}%)")

    return df

def load_and_clean_data(filepath):
    """åŠ è½½å¹¶æ¸…ç†æ•°æ®ï¼Œå¤„ç†æ—¶åŒºé—®é¢˜"""

    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {filepath}")

    # è¯»å–CSVæ–‡ä»¶ï¼Œä¸è‡ªåŠ¨è§£ææ—¥æœŸï¼ˆæˆ‘ä»¬è‡ªå·±å¤„ç†ï¼‰
    df = pd.read_csv(filepath)

    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {df.shape[0]}è¡Œ, {df.shape[1]}åˆ—")

    # å¤„ç†æ—¶é—´åˆ— - æ–¹æ³•1ï¼šç»Ÿä¸€è½¬æ¢ä¸ºå¸¦æ—¶åŒºçš„datetime
    time_columns = ['created_at', 'updated_at', 'pushed_at']

    for col in time_columns:
        if col in df.columns:
            print(f"  å¤„ç† {col} åˆ—...")

            # æ–¹æ³•Aï¼šè½¬æ¢ä¸ºå¸¦UTCæ—¶åŒºçš„datetime
            df[col] = pd.to_datetime(df[col], utc=True, errors='coerce')

            # æ£€æŸ¥è½¬æ¢ç»“æœ
            null_count = df[col].isnull().sum()
            if null_count > 0:
                print(f"    âš ï¸  {col}åˆ—æœ‰{null_count}ä¸ªæ— æ³•è§£æçš„æ—¶é—´å€¼")

    return df


def enhance_data_quality(df):
    """æå‡æ•°æ®è´¨é‡ - ä¿®å¤ç‰ˆæœ¬"""

    print("\nğŸ”§ å¼€å§‹æ•°æ®è´¨é‡æå‡...")

    # 1. å¤„ç†languageç¼ºå¤±
    df['language'] = df['language'].fillna('Unknown')

    # 2. å¤„ç†descriptionç¼ºå¤±
    df['description'] = df['description'].fillna('')

    # 3. å¤„ç†topicsç¼ºå¤±
    df['topics'] = df['topics'].fillna('')

    # 4. å¤„ç†sourceç¼ºå¤±
    df['source'] = df.get('source', 'github_relaxed')

    print(f"âœ… æ•°æ®è´¨é‡æå‡å®Œæˆ")
    print(f"   ç¼ºå¤±å€¼ç»Ÿè®¡:")
    for col in ['language', 'description', 'topics', 'source']:
        if col in df.columns:
            missing = df[col].isnull().sum()
            pct = missing / len(df) * 100
            print(f"     {col}: {missing}ä¸ªç¼ºå¤± ({pct:.1f}%)")

    return df


# ========== ä¸»æ‰§è¡Œæµç¨‹ ==========
if __name__ == "__main__":
    # 1. åŠ è½½æ•°æ®
    df = load_and_clean_data('../../data/raw/expanded_repositories_702_20251231_105833.csv')  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶å

    # 2. æ•°æ®è´¨é‡æå‡
    df = enhance_data_quality(df)

    # 3. è°ƒæ•´æ´»è·ƒåº¦åˆ†ç±»ï¼ˆä½¿ç”¨ä¿®å¤åçš„å‡½æ•°ï¼‰
    df = refine_activity_classification(df)

    # 4. è®¡ç®—é¡¹ç›®å¹´é¾„ï¼ˆåŒæ ·éœ€è¦å¤„ç†æ—¶åŒºï¼‰
    print("\nğŸ“… è®¡ç®—é¡¹ç›®å¹´é¾„...")
    current_time_utc = pd.Timestamp.now(tz='UTC')
    df['project_age_days'] = (current_time_utc - df['created_at']).dt.days
    df['project_age_months'] = df['project_age_days'] / 30.44

    print(f"  é¡¹ç›®å¹´é¾„ç»Ÿè®¡:")
    print(f"    å¹³å‡ {df['project_age_months'].mean():.1f} ä¸ªæœˆ")
    print(f"    èŒƒå›´ {df['project_age_months'].min():.1f} - {df['project_age_months'].max():.1f} ä¸ªæœˆ")

    # 5. ä¿å­˜æ¸…ç†åçš„æ•°æ®
    output_file = '../../data/processed/cleaned_repositories.csv'
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ æ¸…ç†åçš„æ•°æ®å·²ä¿å­˜è‡³: {output_file}")

    # 6. æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ¯ æœ€ç»ˆæ•°æ®è´¨é‡æ€»ç»“")
    print("=" * 60)
    print(f"æ€»é¡¹ç›®æ•°: {len(df)}")
    print(f"è¯­è¨€ç§ç±»: {df['language'].nunique()}")
    print(f"Starä¸­ä½æ•°: {df['stargazers_count'].median()}")
    print(f"é›¶Staré¡¹ç›®: {(df['stargazers_count'] == 0).sum()} ({(df['stargazers_count'] == 0).mean() * 100:.1f}%)")

    # æ´»è·ƒåº¦è¯¦ç»†åˆ†å¸ƒ
    if 'activity_level_refined' in df.columns:
        print(f"\næ´»è·ƒåº¦åˆ†å¸ƒ:")
        for level in ['éå¸¸æ´»è·ƒ(â‰¤7å¤©)', 'æ´»è·ƒ(8-30å¤©)', 'ä¸€èˆ¬æ´»è·ƒ(31-90å¤©)', 'ä½æ´»è·ƒ(91-180å¤©)', 'å¯èƒ½åœæ»(>180å¤©)']:
            if level in df['activity_level_refined'].values:
                count = (df['activity_level_refined'] == level).sum()
                pct = count / len(df) * 100
                print(f"  {level}: {count} ({pct:.1f}%)")