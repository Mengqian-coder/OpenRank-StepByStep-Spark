"""
ç»´æŠ¤æ•ˆç‡ä¸åä½œè´¨é‡è¯„ä¼°æ¨¡å—
åŒ…å«ä¸‰ä¸ªå­ç»´åº¦ï¼šé—®é¢˜è§£å†³æ•ˆç‡ã€ä»£ç å®¡æŸ¥è´¨é‡ã€åä½œè§„èŒƒåŒ–ç¨‹åº¦
"""

import pandas as pd
import numpy as np
import re
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from .base_calculator import BaseMetricCalculator


class MaintenanceEfficiencyCalculator(BaseMetricCalculator):
    """ç»´æŠ¤æ•ˆç‡ä¸åä½œè´¨é‡è®¡ç®—å™¨"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)

        # å­ç»´åº¦æƒé‡é…ç½®
        self.weights = {
            'issue_resolution_efficiency': 0.40,  # é—®é¢˜è§£å†³æ•ˆç‡
            'code_review_quality': 0.35,  # ä»£ç å®¡æŸ¥è´¨é‡
            'collaboration_standardization': 0.25,  # åä½œè§„èŒƒåŒ–ç¨‹åº¦
        }

        # åä½œç›¸å…³å…³é”®è¯
        self.collaboration_keywords = {
            # ä»£ç å®¡æŸ¥ç›¸å…³
            'code_review': ['review', 'code review', 'pull request', 'pr', 'merge'],
            'testing': ['test', 'testing', 'unit test', 'integration test', 'ci'],
            'documentation': ['doc', 'documentation', 'wiki', 'readme', 'guide'],

            # æµç¨‹è§„èŒƒåŒ–
            'templates': ['template', 'issue template', 'pr template', 'contributing'],
            'guidelines': ['guideline', 'style guide', 'code style', 'lint'],
            'standards': ['standard', 'convention', 'best practice', 'policy'],

            # ç¤¾åŒºç®¡ç†
            'community': ['community', 'contributor', 'maintainer', 'owner'],
            'communication': ['discussion', 'chat', 'forum', 'gitter', 'slack'],
            'governance': ['governance', 'decision', 'leadership', 'maintainership'],
        }

        # é—®é¢˜è§£å†³ç›¸å…³æŒ‡æ ‡
        self.issue_keywords = {
            'bug': ['bug', 'fix', 'error', 'issue', 'bugfix'],
            'feature': ['feature', 'enhancement', 'improvement', 'new'],
            'question': ['question', 'help', 'support', 'how to'],
            'documentation': ['doc', 'documentation', 'readme', 'wiki'],
        }

        # ä»£ç å®¡æŸ¥å®è·µè¯„åˆ†
        self.review_practice_scores = {
            'mandatory_review': 20,  # è¦æ±‚ä»£ç å®¡æŸ¥
            'automated_checks': 15,  # è‡ªåŠ¨åŒ–æ£€æŸ¥
            'review_templates': 10,  # å®¡æŸ¥æ¨¡æ¿
            'review_guidelines': 10,  # å®¡æŸ¥æŒ‡å—
            'review_metrics': 5,  # å®¡æŸ¥æŒ‡æ ‡è¿½è¸ª
        }

    def calculate(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        è®¡ç®—ç»´æŠ¤æ•ˆç‡ä¸åä½œè´¨é‡çš„ä¸‰ä¸ªå­æŒ‡æ ‡

        Parameters:
        -----------
        df : pd.DataFrame
            åŒ…å«é¡¹ç›®æ•°æ®çš„DataFrame

        Returns:
        --------
        pd.DataFrame
            æ·»åŠ äº†ç»´æŠ¤æ•ˆç‡ç›¸å…³åˆ—çš„DataFrame
        """

        print("âš™ï¸  å¼€å§‹è®¡ç®—ç»´æŠ¤æ•ˆç‡ä¸åä½œè´¨é‡...")

        # 1. é—®é¢˜è§£å†³æ•ˆç‡ (ISE)
        print("  è®¡ç®—å­ç»´åº¦1: é—®é¢˜è§£å†³æ•ˆç‡")
        df['ise_score'] = self._calculate_issue_resolution_efficiency(df)

        # 2. ä»£ç å®¡æŸ¥è´¨é‡ (CRQ)
        print("  è®¡ç®—å­ç»´åº¦2: ä»£ç å®¡æŸ¥è´¨é‡")
        df['crq_score'] = self._calculate_code_review_quality(df)

        # 3. åä½œè§„èŒƒåŒ–ç¨‹åº¦ (CSD)
        print("  è®¡ç®—å­ç»´åº¦3: åä½œè§„èŒƒåŒ–ç¨‹åº¦")
        df['csd_score'] = self._calculate_collaboration_standardization(df)

        # 4. ç»¼åˆç»´æŠ¤æ•ˆç‡å¾—åˆ†
        df['maintenance_efficiency_score'] = (
                self.weights['issue_resolution_efficiency'] * df['ise_score'] +
                self.weights['code_review_quality'] * df['crq_score'] +
                self.weights['collaboration_standardization'] * df['csd_score']
        )

        # ç¡®ä¿åˆ†æ•°åœ¨0-100èŒƒå›´å†…
        df['maintenance_efficiency_score'] = df['maintenance_efficiency_score'].clip(0, 100)

        print(f"âœ… ç»´æŠ¤æ•ˆç‡è®¡ç®—å®Œæˆ")
        print(f"  å¹³å‡åˆ†: {df['maintenance_efficiency_score'].mean():.2f}")
        print(
            f"  èŒƒå›´: {df['maintenance_efficiency_score'].min():.2f} - {df['maintenance_efficiency_score'].max():.2f}")

        return df

    def _calculate_issue_resolution_efficiency(self, df: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—é—®é¢˜è§£å†³æ•ˆç‡è¯„åˆ†

        åŸºäºç°æœ‰æ•°æ®æ¨æ–­issueè§£å†³æ•ˆç‡ï¼š
        1. open_issues_countä¸é¡¹ç›®è§„æ¨¡çš„å…³ç³»
        2. é¡¹ç›®æ´»è·ƒåº¦ä¸issueæ•°é‡çš„å…³ç³»
        3. æè¿°ä¸­æ˜¯å¦æåŠissueå¤„ç†ç­–ç•¥
        """

        scores = []

        for _, row in df.iterrows():
            score = 50  # åŸºç¡€åˆ†

            # 1. åŸºäºopen_issues_countçš„è¯„ä¼° (0-40åˆ†)
            issues_score = self._evaluate_issues_count(
                row.get('open_issues_count', 0),
                row.get('stargazers_count', 0),
                row.get('forks_count', 0)
            )
            score += issues_score

            # 2. åŸºäºé¡¹ç›®å¹´é¾„å’Œæ›´æ–°é¢‘ç‡ (0-30åˆ†)
            activity_score = self._evaluate_activity_for_issue_resolution(
                row.get('created_at'),
                row.get('pushed_at'),
                row.get('updated_at')
            )
            score += activity_score

            # 3. åŸºäºæè¿°çš„issueç®¡ç†å®è·µ (0-20åˆ†)
            practice_score = self._evaluate_issue_practices(
                row.get('description', ''),
                row.get('topics', '')
            )
            score += practice_score

            # 4. åŸºäºè¯­è¨€çš„é¡¹ç›®è§„æ¨¡è°ƒæ•´ (-10 to +10åˆ†)
            adjustment = self._adjust_by_language_and_scale(
                row.get('language', 'Unknown'),
                row.get('stargazers_count', 0)
            )
            score += adjustment

            scores.append(min(100, max(0, score)))

        return pd.Series(scores, index=df.index)

    def _evaluate_issues_count(self, issues_count: int, stars: int, forks: int) -> float:
        """
        è¯„ä¼°issueæ•°é‡ä¸é¡¹ç›®è§„æ¨¡çš„å…³ç³»

        é€»è¾‘ï¼š
        - å®Œå…¨æ²¡æœ‰issueï¼šå¯èƒ½é¡¹ç›®å¤ªæ–°æˆ–æ— äººä½¿ç”¨ï¼ˆä¸­ç­‰åˆ†æ•°ï¼‰
        - issueæ•°é‡ä¸star/forkæ¯”ä¾‹åˆç†ï¼šé«˜åˆ†
        - issueè¿‡å¤šä½†star/forkå°‘ï¼šå¯èƒ½ç»´æŠ¤è·Ÿä¸ä¸Š
        - issueæå°‘ä½†star/forkå¤šï¼šå¯èƒ½issueç®¡ç†ä¸¥æ ¼
        """

        if issues_count == 0:
            if stars == 0 and forks == 0:
                return 0  # é¡¹ç›®æ— äººä½¿ç”¨
            elif stars < 10 and forks < 5:
                return 20  # å°é¡¹ç›®ï¼Œåˆç†
            else:
                return 10  # æœ‰ä¸€å®šè§„æ¨¡ä½†æ— issueï¼Œå¯èƒ½issueè¢«å…³é—­æˆ–è½¬ç§»

        # è®¡ç®—issueä¸é¡¹ç›®è§„æ¨¡çš„ç›¸å¯¹æ¯”ä¾‹
        project_size = stars + forks * 2 + 1  # åŠ 1é¿å…é™¤é›¶ï¼Œforkæƒé‡æ›´é«˜

        # ç†æƒ³æ¯”ä¾‹ï¼šæ¯100ä¸ªstar/forkæœ‰1-5ä¸ªopen issue
        ideal_ratio_min = 0.01
        ideal_ratio_max = 0.05

        actual_ratio = issues_count / project_size

        if actual_ratio < ideal_ratio_min:
            # issueå¤ªå°‘ï¼Œå¯èƒ½ç»´æŠ¤ä¸¥æ ¼æˆ–issueè¢«å¿«é€Ÿè§£å†³
            return 35
        elif actual_ratio <= ideal_ratio_max:
            # åœ¨ç†æƒ³èŒƒå›´å†…
            return 40
        elif actual_ratio <= ideal_ratio_max * 2:
            # ç¨å¤šï¼Œä½†å¯æ¥å—
            return 25
        elif actual_ratio <= ideal_ratio_max * 5:
            # è¾ƒå¤šï¼Œå¯èƒ½ç»´æŠ¤å‹åŠ›å¤§
            return 15
        else:
            # å¤ªå¤šï¼Œç»´æŠ¤å¯èƒ½è·Ÿä¸ä¸Š
            return 5

    def _evaluate_activity_for_issue_resolution(self, created_at, pushed_at, updated_at) -> float:
        """
        åŸºäºé¡¹ç›®æ´»è·ƒåº¦è¯„ä¼°issueè§£å†³å¯èƒ½æ€§
        """

        if pd.isna(created_at) or pd.isna(pushed_at):
            return 10  # é»˜è®¤åˆ†

        try:
            current_time = pd.Timestamp.now(tz='UTC')

            # 1. é¡¹ç›®å¹´é¾„
            age_days = (current_time - created_at).days
            age_months = age_days / 30.44

            # 2. æœ€è¿‘æ›´æ–°
            days_since_update = (current_time - pushed_at).days

            # 3. æ›´æ–°é¢‘ç‡è¯„åˆ†
            if days_since_update <= 7:
                update_score = 15  # éå¸¸æ´»è·ƒ
            elif days_since_update <= 30:
                update_score = 12  # æ´»è·ƒ
            elif days_since_update <= 90:
                update_score = 8  # ä¸€èˆ¬æ´»è·ƒ
            elif days_since_update <= 180:
                update_score = 4  # ä¸å¤ªæ´»è·ƒ
            else:
                update_score = 0  # ä¸æ´»è·ƒ

            # 4. é¡¹ç›®æˆç†Ÿåº¦è¯„åˆ†ï¼ˆè€é¡¹ç›®æ›´å¯èƒ½æœ‰ç¨³å®šæµç¨‹ï¼‰
            if age_months < 3:
                maturity_score = 5  # å¤ªæ–°
            elif age_months < 12:
                maturity_score = 10  # æœ‰ä¸€å®šå†å²
            else:
                maturity_score = 15  # æˆç†Ÿé¡¹ç›®

            return update_score + maturity_score

        except:
            return 10

    def _evaluate_issue_practices(self, description: str, topics: str) -> float:
        """è¯„ä¼°issueç®¡ç†å®è·µ"""

        score = 0
        text_to_check = ""

        if pd.notna(description):
            text_to_check += str(description).lower() + " "
        if pd.notna(topics):
            text_to_check += str(topics).lower()

        # æ£€æŸ¥issueç®¡ç†å…³é”®è¯
        issue_keywords = [
            'issue', 'bug', 'feature request', 'bug report',
            'support', 'help', 'question', 'discussion'
        ]

        found_keywords = 0
        for keyword in issue_keywords:
            if keyword in text_to_check:
                found_keywords += 1

        # æ¯æ‰¾åˆ°ä¸€ä¸ªå…³é”®è¯åŠ 2åˆ†ï¼Œæœ€å¤š10åˆ†
        score += min(10, found_keywords * 2)

        # æ£€æŸ¥issueæ¨¡æ¿æˆ–æµç¨‹
        template_keywords = ['template', 'form', 'guideline', 'process']
        for keyword in template_keywords:
            if keyword in text_to_check:
                score += 5
                break

        # æ£€æŸ¥æ ‡ç­¾ç³»ç»Ÿ
        label_keywords = ['label', 'tag', 'categor', 'priority']
        for keyword in label_keywords:
            if keyword in text_to_check:
                score += 5
                break

        return min(20, score)

    def _adjust_by_language_and_scale(self, language: str, stars: int) -> float:
        """æ ¹æ®è¯­è¨€å’Œé¡¹ç›®è§„æ¨¡è°ƒæ•´åˆ†æ•°"""

        adjustment = 0

        # ä¸åŒè¯­è¨€ç¤¾åŒºçš„issueæ–‡åŒ–ä¸åŒ
        language_adjustments = {
            'Rust': 5,  # Rustç¤¾åŒºä»¥ä¸¥è°¨è‘—ç§°
            'Go': 3,  # Goç¤¾åŒºé‡è§†ç®€æ´
            'Python': 0,  # Pythonç¤¾åŒºé€‚ä¸­
            'JavaScript': -2,  # JSé¡¹ç›®å¯èƒ½issueè¾ƒå¤š
            'TypeScript': 0,
            'Java': 2,
            'C++': 2,
            'Unknown': -5,
        }

        adjustment += language_adjustments.get(language, 0)

        # æ ¹æ®é¡¹ç›®è§„æ¨¡è°ƒæ•´
        if stars > 1000:
            adjustment -= 5  # å¤§é¡¹ç›®issueç®¡ç†æ›´éš¾
        elif stars > 100:
            adjustment += 0  # ä¸­ç­‰é¡¹ç›®é€‚ä¸­
        else:
            adjustment += 3  # å°é¡¹ç›®æ›´å®¹æ˜“ç®¡ç†

        return adjustment

    def _calculate_code_review_quality(self, df: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—ä»£ç å®¡æŸ¥è´¨é‡è¯„åˆ†

        åŸºäºæè¿°å’Œä¸»é¢˜æ¨æ–­ä»£ç å®¡æŸ¥å®è·µï¼š
        1. æ˜¯å¦æœ‰ä»£ç å®¡æŸ¥ç›¸å…³æè¿°
        2. æ˜¯å¦æœ‰è‡ªåŠ¨åŒ–æµ‹è¯•/CI/CD
        3. æ˜¯å¦æœ‰è´¡çŒ®æŒ‡å—
        """

        scores = []

        for _, row in df.iterrows():
            score = 40  # åŸºç¡€åˆ†

            # 1. ä»æè¿°å’Œä¸»é¢˜ä¸­æå–ä»£ç å®¡æŸ¥å…³é”®è¯ (0-30åˆ†)
            review_score = self._extract_review_keywords(
                row.get('description', ''),
                row.get('topics', '')
            )
            score += review_score

            # 2. åŸºäºå·¥ç¨‹å®è·µæ¨æ–­ (0-20åˆ†)
            practice_score = self._infer_engineering_practices(
                row.get('description', ''),
                row.get('topics', '')
            )
            score += practice_score

            # 3. åŸºäºé¡¹ç›®æ´»è·ƒåº¦å’Œè§„æ¨¡ (0-10åˆ†)
            activity_score = self._evaluate_review_activity(
                row.get('stargazers_count', 0),
                row.get('forks_count', 0),
                row.get('open_issues_count', 0)
            )
            score += activity_score

            scores.append(min(100, max(0, score)))

        return pd.Series(scores, index=df.index)

    def _extract_review_keywords(self, description: str, topics: str) -> float:
        """ä»æ–‡æœ¬ä¸­æå–ä»£ç å®¡æŸ¥å…³é”®è¯"""

        score = 0
        text_to_check = ""

        if pd.notna(description):
            text_to_check += str(description).lower() + " "
        if pd.notna(topics):
            text_to_check += str(topics).lower()

        # ä»£ç å®¡æŸ¥ç›´æ¥å…³é”®è¯
        review_direct_keywords = [
            'code review', 'pull request review', 'pr review',
            'review process', 'merge request', 'mr'
        ]

        for keyword in review_direct_keywords:
            if keyword in text_to_check:
                score += 10
                break  # æ‰¾åˆ°ç›´æ¥è¯æ®å°±åŠ åˆ†

        # å®¡æŸ¥ç›¸å…³å®è·µ
        review_practice_keywords = [
            'approval', 'reviewer', 'maintainer review',
            'required review', 'mandatory review'
        ]

        found_practices = 0
        for keyword in review_practice_keywords:
            if keyword in text_to_check:
                found_practices += 1

        score += min(10, found_practices * 3)

        # è‡ªåŠ¨åŒ–å®¡æŸ¥å·¥å…·
        tool_keywords = [
            'sonarqube', 'codeclimate', 'codacy', 'reviewable',
            'pullapprove', 'codefactor', 'houndci'
        ]

        for keyword in tool_keywords:
            if keyword in text_to_check:
                score += 5
                break

        return min(30, score)

    def _infer_engineering_practices(self, description: str, topics: str) -> float:
        """ä»å·¥ç¨‹å®è·µæ¨æ–­ä»£ç å®¡æŸ¥è´¨é‡"""

        score = 0
        text_to_check = ""

        if pd.notna(description):
            text_to_check += str(description).lower() + " "
        if pd.notna(topics):
            text_to_check += str(topics).lower()

        # CI/CDå®è·µï¼ˆé€šå¸¸ä¸ä»£ç å®¡æŸ¥ç»“åˆï¼‰
        ci_cd_keywords = ['ci', 'cd', 'continuous integration', 'continuous delivery']
        for keyword in ci_cd_keywords:
            if keyword in text_to_check:
                score += 5
                break

        # æµ‹è¯•å®è·µ
        test_keywords = ['test', 'testing', 'unit test', 'integration test', 'coverage']
        test_count = 0
        for keyword in test_keywords:
            if keyword in text_to_check:
                test_count += 1

        score += min(5, test_count)

        # ä»£ç è´¨é‡å·¥å…·
        quality_keywords = ['lint', 'linter', 'static analysis', 'code quality']
        for keyword in quality_keywords:
            if keyword in text_to_check:
                score += 5
                break

        # è´¡çŒ®æŒ‡å—ï¼ˆé€šå¸¸åŒ…å«å®¡æŸ¥æµç¨‹ï¼‰
        contributing_keywords = ['contributing', 'contribute', 'contributor']
        for keyword in contributing_keywords:
            if keyword in text_to_check:
                score += 5
                break

        return min(20, score)

    def _evaluate_review_activity(self, stars: int, forks: int, issues: int) -> float:
        """åŸºäºé¡¹ç›®æ´»è·ƒåº¦è¯„ä¼°ä»£ç å®¡æŸ¥å¯èƒ½æ€§"""

        # é¡¹ç›®è§„æ¨¡è¶Šå¤§ï¼Œè¶Šå¯èƒ½éœ€è¦ä»£ç å®¡æŸ¥
        project_scale = stars + forks * 0.5

        if project_scale < 10:
            return 3  # å°é¡¹ç›®å¯èƒ½æ²¡æœ‰æ­£å¼å®¡æŸ¥
        elif project_scale < 100:
            return 6  # ä¸­ç­‰é¡¹ç›®å¯èƒ½å¼€å§‹æœ‰å®¡æŸ¥
        elif project_scale < 1000:
            return 8  # è¾ƒå¤§é¡¹ç›®åº”è¯¥æœ‰å®¡æŸ¥
        else:
            return 10  # å¤§é¡¹ç›®å¿…é¡»æœ‰å®¡æŸ¥

    def _calculate_collaboration_standardization(self, df: pd.DataFrame) -> pd.Series:
        """
        è®¡ç®—åä½œè§„èŒƒåŒ–ç¨‹åº¦è¯„åˆ†

        è¯„ä¼°é¡¹ç›®åä½œæµç¨‹çš„è§„èŒƒåŒ–ç¨‹åº¦ï¼š
        1. æ˜¯å¦æœ‰æ˜ç¡®çš„è´¡çŒ®æŒ‡å—
        2. æ˜¯å¦æœ‰æ¨¡æ¿ç³»ç»Ÿ
        3. æ˜¯å¦æœ‰è¡Œä¸ºå‡†åˆ™
        4. æ˜¯å¦æœ‰ç‰ˆæœ¬ç®¡ç†è§„èŒƒ
        """

        scores = []

        for _, row in df.iterrows():
            score = 30  # åŸºç¡€åˆ†

            # 1. è´¡çŒ®æŒ‡å—å’Œæ¨¡æ¿ (0-30åˆ†)
            guideline_score = self._evaluate_guidelines_and_templates(
                row.get('description', ''),
                row.get('topics', '')
            )
            score += guideline_score

            # 2. ç¤¾åŒºç®¡ç†è§„èŒƒ (0-20åˆ†)
            community_score = self._evaluate_community_management(
                row.get('description', ''),
                row.get('topics', '')
            )
            score += community_score

            # 3. ç‰ˆæœ¬å’Œå‘å¸ƒç®¡ç† (0-20åˆ†)
            release_score = self._evaluate_release_management(
                row.get('description', ''),
                row.get('topics', '')
            )
            score += release_score

            scores.append(min(100, max(0, score)))

        return pd.Series(scores, index=df.index)

    def _evaluate_guidelines_and_templates(self, description: str, topics: str) -> float:
        """è¯„ä¼°è´¡çŒ®æŒ‡å—å’Œæ¨¡æ¿"""

        score = 0
        text_to_check = ""

        if pd.notna(description):
            text_to_check += str(description).lower() + " "
        if pd.notna(topics):
            text_to_check += str(topics).lower()

        # è´¡çŒ®æŒ‡å—
        contributing_terms = [
            'contributing', 'contribution guidelines', 'contributor guide',
            'how to contribute', 'development guide'
        ]

        for term in contributing_terms:
            if term in text_to_check:
                score += 10
                break

        # æ¨¡æ¿
        template_terms = [
            'template', 'issue template', 'pull request template',
            'bug report template', 'feature request template'
        ]

        for term in template_terms:
            if term in text_to_check:
                score += 8
                break

        # ä»£ç é£æ ¼æŒ‡å—
        style_terms = ['style guide', 'coding style', 'code convention', 'lint']
        for term in style_terms:
            if term in text_to_check:
                score += 7
                break

        # æ–‡æ¡£æŒ‡å—
        doc_terms = ['documentation', 'doc', 'readme', 'wiki']
        doc_count = 0
        for term in doc_terms:
            if term in text_to_check:
                doc_count += 1

        score += min(5, doc_count * 2)

        return min(30, score)

    def _evaluate_community_management(self, description: str, topics: str) -> float:
        """è¯„ä¼°ç¤¾åŒºç®¡ç†è§„èŒƒ"""

        score = 0
        text_to_check = ""

        if pd.notna(description):
            text_to_check += str(description).lower() + " "
        if pd.notna(topics):
            text_to_check += str(topics).lower()

        # è¡Œä¸ºå‡†åˆ™
        coc_terms = [
            'code of conduct', 'coc', 'conduct',
            'community guidelines', 'community standards'
        ]

        for term in coc_terms:
            if term in text_to_check:
                score += 10
                break

        # æ²Ÿé€šæ¸ é“
        communication_terms = [
            'discussion', 'forum', 'chat', 'gitter', 'slack',
            'discord', 'matrix', 'irc', 'mailing list'
        ]

        comm_count = 0
        for term in communication_terms:
            if term in text_to_check:
                comm_count += 1

        score += min(5, comm_count * 2)

        # å†³ç­–æµç¨‹
        decision_terms = ['governance', 'decision', 'rfc', 'proposal']
        for term in decision_terms:
            if term in text_to_check:
                score += 5
                break

        return min(20, score)

    def _evaluate_release_management(self, description: str, topics: str) -> float:
        """è¯„ä¼°ç‰ˆæœ¬å’Œå‘å¸ƒç®¡ç†"""

        score = 0
        text_to_check = ""

        if pd.notna(description):
            text_to_check += str(description).lower() + " "
        if pd.notna(topics):
            text_to_check += str(topics).lower()

        # ç‰ˆæœ¬ç®¡ç†
        version_terms = [
            'version', 'release', 'semver', 'semantic versioning',
            'changelog', 'release notes'
        ]

        version_count = 0
        for term in version_terms:
            if term in text_to_check:
                version_count += 1

        score += min(10, version_count * 3)

        # å‘å¸ƒæµç¨‹
        release_terms = ['release process', 'deploy', 'publish', 'distribution']
        for term in release_terms:
            if term in text_to_check:
                score += 5
                break

        # ç¨³å®šæ€§ä¿è¯
        stability_terms = ['stable', 'production', 'enterprise', 'reliable']
        for term in stability_terms:
            if term in text_to_check:
                score += 5
                break

        return min(20, score)

    def generate_detailed_report(self, df: pd.DataFrame, top_n: int = 10) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»´æŠ¤æ•ˆç‡è¯¦ç»†æŠ¥å‘Š

        Parameters:
        -----------
        df : pd.DataFrame
            åŒ…å«ç»´æŠ¤æ•ˆç‡è¯„åˆ†çš„DataFrame
        top_n : int
            æ˜¾ç¤ºå‰Nåé¡¹ç›®

        Returns:
        --------
        Dict[str, Any]
            åŒ…å«è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """

        report = {
            'summary': {
                'total_projects': len(df),
                'avg_efficiency_score': df['maintenance_efficiency_score'].mean(),
                'median_efficiency_score': df['maintenance_efficiency_score'].median(),
                'std_efficiency_score': df['maintenance_efficiency_score'].std(),
            },
            'subdimension_analysis': {},
            'top_performers': [],
            'recommendations': []
        }

        # å­ç»´åº¦åˆ†æ
        subdims = ['ise_score', 'crq_score', 'csd_score']
        subdim_names = {
            'ise_score': 'é—®é¢˜è§£å†³æ•ˆç‡',
            'crq_score': 'ä»£ç å®¡æŸ¥è´¨é‡',
            'csd_score': 'åä½œè§„èŒƒåŒ–'
        }

        for dim in subdims:
            if dim in df.columns:
                report['subdimension_analysis'][subdim_names[dim]] = {
                    'average': df[dim].mean(),
                    'median': df[dim].median(),
                    'std': df[dim].std(),
                    'top_5_avg': df.nlargest(5, dim)[dim].mean()
                }

        # è¡¨ç°æœ€ä½³çš„é¡¹ç›®
        if 'maintenance_efficiency_score' in df.columns:
            top_projects = df.nlargest(top_n, 'maintenance_efficiency_score')[
                ['full_name', 'language', 'stargazers_count', 'open_issues_count',
                 'maintenance_efficiency_score', 'ise_score', 'crq_score', 'csd_score']
            ]

            for _, row in top_projects.iterrows():
                report['top_performers'].append({
                    'full_name': row['full_name'],
                    'language': row['language'],
                    'stars': int(row['stargazers_count']),
                    'open_issues': int(row['open_issues_count']),
                    'total_score': round(row['maintenance_efficiency_score'], 2),
                    'ise_score': round(row['ise_score'], 2),
                    'crq_score': round(row['crq_score'], 2),
                    'csd_score': round(row['csd_score'], 2)
                })

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        report['recommendations'] = self._generate_efficiency_recommendations(df)

        return report

    def _generate_efficiency_recommendations(self, df: pd.DataFrame) -> List[Dict[str, str]]:
        """ç”Ÿæˆé’ˆå¯¹ç»´æŠ¤æ•ˆç‡çš„æ”¹è¿›å»ºè®®"""

        recommendations = []

        # 1. æ£€æŸ¥æ™®éé—®é¢˜
        subdim_columns = ['ise_score', 'crq_score', 'csd_score']
        subdim_names = ['é—®é¢˜è§£å†³æ•ˆç‡', 'ä»£ç å®¡æŸ¥è´¨é‡', 'åä½œè§„èŒƒåŒ–']

        low_dimensions = []
        for col, name in zip(subdim_columns, subdim_names):
            if col in df.columns and df[col].mean() < 50:
                low_dimensions.append(name)

        if low_dimensions:
            recommendations.append({
                "priority": "é«˜",
                "issue": f"å¤šä¸ªå­ç»´åº¦å¾—åˆ†åä½",
                "suggestion": f"é‡ç‚¹å…³æ³¨: {', '.join(low_dimensions)}",
                "action": "åˆ†æä½åˆ†é¡¹ç›®çš„å…·ä½“åŸå› ï¼Œæä¾›æ”¹è¿›æ¨¡æ¿"
            })

        # 2. æ£€æŸ¥issueç®¡ç†
        if 'open_issues_count' in df.columns:
            high_issue_projects = df[df['open_issues_count'] > 50]
            if len(high_issue_projects) > 0:
                recommendations.append({
                    "priority": "ä¸­",
                    "issue": f"{len(high_issue_projects)} ä¸ªé¡¹ç›®open issueè¿‡å¤š",
                    "suggestion": "å»ºç«‹issueåˆ†ç±»å’Œä¼˜å…ˆçº§ç³»ç»Ÿ",
                    "action": "å¼•å…¥issueæ¨¡æ¿å’Œè‡ªåŠ¨åŒ–æ ‡ç­¾"
                })

        # 3. æ£€æŸ¥ç¼ºä¹åä½œè§„èŒƒ
        if 'description' in df.columns:
            no_description = df[df['description'].isna() | (df['description'].str.len() < 20)]
            if len(no_description) > 0:
                recommendations.append({
                    "priority": "ä¸­",
                    "issue": f"{len(no_description)} ä¸ªé¡¹ç›®ç¼ºä¹è¯¦ç»†æè¿°",
                    "suggestion": "å®Œå–„é¡¹ç›®æè¿°ï¼Œæ˜ç¡®è´¡çŒ®æ–¹å¼",
                    "action": "æä¾›READMEæ¨¡æ¿å’Œè´¡çŒ®æŒ‡å—ç¤ºä¾‹"
                })

        # 4. åŸºäºè¯­è¨€çš„åˆ†æ
        if 'language' in df.columns and 'maintenance_efficiency_score' in df.columns:
            lang_stats = []
            for lang in df['language'].unique():
                if pd.notna(lang) and lang != 'Unknown':
                    lang_df = df[df['language'] == lang]
                    if len(lang_df) >= 3:
                        avg_score = lang_df['maintenance_efficiency_score'].mean()
                        lang_stats.append((lang, avg_score, len(lang_df)))

            # æ‰¾å‡ºè¡¨ç°æœ€å·®çš„è¯­è¨€
            if lang_stats:
                lang_stats.sort(key=lambda x: x[1])
                worst_lang, worst_score, count = lang_stats[0]
                if worst_score < 50:
                    recommendations.append({
                        "priority": "ä½",
                        "issue": f"{worst_lang} é¡¹ç›®å¹³å‡ç»´æŠ¤æ•ˆç‡è¾ƒä½ ({worst_score:.1f}åˆ†)",
                        "suggestion": f"åˆ†æ{worst_lang}ç”Ÿæ€çš„åä½œç‰¹ç‚¹",
                        "action": f"ä¸º{worst_lang}é¡¹ç›®æä¾›é’ˆå¯¹æ€§çš„åä½œæŒ‡å—"
                    })

        # å¦‚æœæ²¡æœ‰å‘ç°æ˜æ˜¾é—®é¢˜
        if not recommendations:
            recommendations.append({
                "priority": "ä½",
                "issue": "æ— æ˜¾è‘—é—®é¢˜",
                "suggestion": "å½“å‰ç»´æŠ¤æ•ˆç‡æ•´ä½“è‰¯å¥½",
                "action": "ç»§ç»­ä¿æŒç°æœ‰åä½œå®è·µ"
            })

        return recommendations


# æµ‹è¯•å‡½æ•°
def test_maintenance_efficiency_calculator():
    """æµ‹è¯•ç»´æŠ¤æ•ˆç‡è®¡ç®—å™¨"""
    print("ğŸ§ª æµ‹è¯• MaintenanceEfficiencyCalculator...")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = {
        'full_name': ['test/repo1', 'test/repo2', 'test/repo3'],
        'language': ['Python', 'Rust', 'JavaScript'],
        'description': [
            'A well-maintained project with CI/CD and code review',
            'High performance library with contributing guidelines',
            'Simple script with no documentation'
        ],
        'topics': ['python,ci-cd,testing', 'rust,performance,no-std', ''],
        'stargazers_count': [150, 80, 10],
        'forks_count': [30, 15, 2],
        'open_issues_count': [5, 2, 15],
        'created_at': [
            pd.Timestamp('2023-01-01', tz='UTC'),
            pd.Timestamp('2023-06-01', tz='UTC'),
            pd.Timestamp('2024-01-01', tz='UTC')
        ],
        'pushed_at': [
            pd.Timestamp('2024-05-01', tz='UTC'),
            pd.Timestamp('2024-05-15', tz='UTC'),
            pd.Timestamp('2024-01-15', tz='UTC')
        ]
    }

    df_test = pd.DataFrame(test_data)

    # åˆ›å»ºè®¡ç®—å™¨å®ä¾‹
    calculator = MaintenanceEfficiencyCalculator()

    # è®¡ç®—åˆ†æ•°
    result = calculator.calculate(df_test)

    print(f"\næµ‹è¯•ç»“æœ:")
    for idx, row in result.iterrows():
        print(f"  {row['full_name']} ({row['language']}): {row['maintenance_efficiency_score']:.2f}")

    # ç”ŸæˆæŠ¥å‘Š
    report = calculator.generate_detailed_report(result, top_n=2)

    print(f"\næŠ¥å‘Šæ‘˜è¦:")
    print(f"  å¹³å‡åˆ†: {report['summary']['avg_efficiency_score']:.2f}")

    return result


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_result = test_maintenance_efficiency_calculator()
    print("\nâœ… ç»´æŠ¤æ•ˆç‡è®¡ç®—å™¨æµ‹è¯•å®Œæˆ")